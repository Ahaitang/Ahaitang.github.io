[{"content":"","permalink":"http://localhost:1313/posts/env/flume%E5%AE%89%E8%A3%85/","summary":"","title":"Flume安装"},{"content":"","permalink":"http://localhost:1313/posts/env/kafak%E5%AE%89%E8%A3%85/","summary":"","title":"Kafak安装"},{"content":"","permalink":"http://localhost:1313/posts/env/zookeeper%E5%AE%89%E8%A3%85/","summary":"","title":"Zookeeper安装"},{"content":"","permalink":"http://localhost:1313/posts/env/hbase%E5%AE%89%E8%A3%85/","summary":"","title":"Hbase安装"},{"content":"","permalink":"http://localhost:1313/posts/env/hive%E5%AE%89%E8%A3%85/","summary":"","title":"Hive安装"},{"content":"","permalink":"http://localhost:1313/posts/env/spark%E5%AE%89%E8%A3%85/","summary":"","title":"Spark安装"},{"content":"Hadoop 环境配置 修改网络配置 修改hosts 虚拟机安装 JDK 用 XShell 传输工具将 JDK 导入到 opt 目录下面的 software 文件夹下面 解压 JDK 到 /opt/module 目录下\n1 [haitng@hadoop111 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/ 配置 JDK 环境变量\n新建 /etc/profile.d/my_env.sh 文件， 并添加环境变量 1 2 3 4 5 6 [haitng@hadoop111 software]$ sudo vim /etc/profile.d/my_env.sh # 文件内输入以下内容 #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_212 export PATH=$PATH:$JAVA_HOME/bin source 一下 /etc/profile 文件，让新的环境变量 PATH 生效 1 2 [haitng@hadoop111 software]$ source /etc/profile [haitng@hadoop111 software]$ java -version 克隆虚拟机(配置集群) 克隆两台虚拟机（以hadoop112 为例， hadoop113 同理）\n修改 hadoop112 的网络 IP 1 [haitng@hadoop112 ~]$ sudo vim /etc/sysconfig/network-scripts/ifcfg-ens33 重启网络服务，并测试是否成功 1 2 3 4 5 6 7 8 # 重启网络服务 [haitng@hadoop112 ~]$ systemctl restart network # 查看网络 IP [haitng@hadoop112 ~]$ ifconfig # 测试网络 [haitng@hadoop112 ~]$ ping www.baidu.com 修改主机名 1 [haitng@hadoop112 ~]$ vim /etc/hostname hadoop 113同上述操做 配置免密登录 免密登录原理 生成公钥和私钥\n1 2 3 4 5 6 # 回到家目录 [haitng@hadoop111 ~]$ cd ~ # 进入 .ssh 文件 [haitng@hadoop111 ~]$ cd .ssh # 输入下面命令, 并回车三次, 然后生成文件 id_rsa（私钥）、id_rsa.pub（公钥） [haitng@hadoop111 .ssh]$ ssh-keygen -t rsa 将公钥拷贝到要免密登录的目标机器上\n1 2 3 [haitng@hadoop111 .ssh]$ ssh-copy-id haitang111 [haitng@hadoop111 .ssh]$ ssh-copy-id haitang112 [haitng@hadoop111 .ssh]$ ssh-copy-id haitang113 需要在 hadoop112 上采用 haitang 账号配置一下无密登录到 hadoop111、hadoop112、hadoop113 服务器上; 还需要在 hadoop113 上采用 haitang 账号配置一下无密登录到 hadoop111、hadoop112、hadoop113 服务器上; 还需要在 hadoop111 上采用 root 账号，配置一下无密登录到 hadoop111、hadoop112、hadoop113 服务器上。 编写常用脚本 编写集群分发脚本 xsync\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # 返回家目录 [haitng@hadoop111 ~]$ cd ~ # 查看当前环境变量 [haitng@hadoop111 ~]$ echo $PATH # 在家目录创建 bin 文件夹 [haitng@hadoop111 ~]$ mkdir bin [haitng@hadoop111 ~]$ cd bin # 创建集群分发脚本 xsync [haitng@hadoop111 bin]$ vim xsync #!/bin/bash #1. 判断参数个数 if [ $# -lt 1 ] then echo Not Enough Arguement! exit; fi #2. 遍历集群所有机器 for host in hadoop111 hadoop112 hadoop113 do echo ==================== $host ==================== #3. 遍历所有目录，挨个发送 for file in $@ do #4. 判断文件是否存在 if [ -e $file ] then #5. 获取父目录 pdir=$(cd -P $(dirname $file); pwd) #6. 获取当前文件的名称 fname=$(basename $file) ssh $host \u0026#34;mkdir -p $pdir\u0026#34; rsync -av $pdir/$fname $host:$pdir else echo $file does not exists! fi done done # 修改脚本 xsync 具有执行权限 [haitng@hadoop111 bin]$ chmod +x xsync # 将脚本复制到/bin 中，以便全局调用 [haitng@hadoop111 bin]$ sudo cp xsync /bin/ Hadoop 集群启停脚本（包含 HDFS，Yarn，Historyserver）：myhadoop.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 返回家目录下的bin目录 [haitng@hadoop111 ~]$ cd ~ [haitng@hadoop111 ~]$ cd bin # 创建集群启停脚本 myhadoop.sh [haitng@hadoop111 bin]$ vim myhadoop.sh # 脚本内容如下 #!/bin/bash if [ $# -lt 1 ] then echo \u0026#34;No Args Input...\u0026#34; exit ; fi case $1 in \u0026#34;start\u0026#34;) echo \u0026#34; =================== 启动 hadoop 集群 ===================\u0026#34; echo \u0026#34; --------------- 启动 hdfs ---------------\u0026#34; ssh hadoop111 \u0026#34;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh\u0026#34; echo \u0026#34; --------------- 启动 yarn ---------------\u0026#34; ssh hadoop112 \u0026#34;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh\u0026#34; echo \u0026#34; --------------- 启动 historyserver ---------------\u0026#34; ssh hadoop111 \u0026#34;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver\u0026#34; ;; \u0026#34;stop\u0026#34;) echo \u0026#34; =================== 关闭 hadoop 集群 ===================\u0026#34; echo \u0026#34; --------------- 关闭 historyserver ---------------\u0026#34; ssh hadoop111 \u0026#34;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver\u0026#34; echo \u0026#34; --------------- 关闭 yarn ---------------\u0026#34; ssh hadoop112 \u0026#34;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh\u0026#34; echo \u0026#34; --------------- 关闭 hdfs ---------------\u0026#34; ssh hadoop111 \u0026#34;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh\u0026#34; ;; *) echo \u0026#34;Input Args Error...\u0026#34; ;; esac # 修改脚本 myhadoop.sh 具有执行权限 [haitng@hadoop111 bin]$ chmod +x myhadoop.sh 查看三台服务器 Java 进程脚本：jpsall\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 返回家目录下的bin目录 [haitng@hadoop111 ~]$ cd ~ [haitng@hadoop111 ~]$ cd bin # 创建 java 进程脚本：jpsall [haitng@hadoop111 bin]$ vim jpsall #!/bin/bash for host in hadoop111 hadoop112 hadoop113 do echo =============== $host =============== ssh $host jps done # 修改脚本 jpsall 具有执行权限 [haitng@hadoop111 bin]$ chmod +x jpsall 虚拟机安装 Hadoop 用 XShell 文件传输工具将 hadoop-3.1.3.tar.gz 导入到 opt 目录下面的 software 文件夹下面 解压安装文件到/opt/module 下面\n1 tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/ 配置 Hadoop 环境变量\n新建 /etc/profile.d/my_env.sh 文件， 并添加环境变量 1 2 3 4 5 6 sudo vim /etc/profile.d/my_env.sh #HADOOP_HOME export HADOOP_HOME=/opt/module/hadoop-3.1.3 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin 2. source 一下 /etc/profile 文件，让新的环境变量 PATH 生效\n1 2 source /etc/profile hadoop version 配置集群文件 此处同时配置了历史服务器与历史服务器\n核心配置文件(core-site.xml) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 vim core-site.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;?xml-stylesheet type=\u0026#34;text/xsl\u0026#34; href=\u0026#34;configuration.xsl\u0026#34;?\u0026gt; \u0026lt;!-- Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file. --\u0026gt; \u0026lt;!-- Put site-specific property overrides in this file. --\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!--指定NameNode的地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://hadoop111:8020\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 指定hadoop数据的存储目录 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/opt/module/hadoop-3.1.3/data\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 配置HDFS网页登录使用的静态用户为haitang --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.http.staticuser.user\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;haitang\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; HDFS 配置文件(hdfs-site.xml) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 vim hdfs-site.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;?xml-stylesheet type=\u0026#34;text/xsl\u0026#34; href=\u0026#34;configuration.xsl\u0026#34;?\u0026gt; \u0026lt;!-- Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file. --\u0026gt; \u0026lt;!-- Put site-specific property overrides in this file. --\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- nn web端访问地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.http-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hadoop111:9870\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 2nn web端访问地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.secondary.http-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hadoop113:9868\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; YARN 配置文件(yarn-site.xml) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 vim yarn-site.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!-- Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file. --\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- Site specific YARN configuration properties --\u0026gt; \u0026lt;!-- 指定MR走shuffle --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.aux-services\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;mapreduce_shuffle\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 指定ResourceManager的地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.hostname\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hadoop112\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 环境变量的继承 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.env-whitelist\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CO NF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP RED_HOME\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 开启日志聚集功能 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.log-aggregation-enable\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 设置日志聚集服务器地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.log.server.url\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;http://hadoop111:19888/jobhistory/logs\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 设置日志保留时间为7天 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.log-aggregation.retain-seconds\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;604800\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; MapReduce 配置文件(mapred-site.xml) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 vim mapred-site.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;?xml-stylesheet type=\u0026#34;text/xsl\u0026#34; href=\u0026#34;configuration.xsl\u0026#34;?\u0026gt; \u0026lt;!-- Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file. --\u0026gt; \u0026lt;!-- Put site-specific property overrides in this file. --\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 指定MapReduce程序运行在Yarn上 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.framework.name\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;yarn\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 历史服务器端地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.jobhistory.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hadoop111:10020\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 历史服务器web端地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.jobhistory.webapp.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hadoop111:19888\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 配置workers 1 2 3 4 5 vim workers hadoop111 hadoop112 hadoop113 启动集群 如果集群是第一次启动，需要在 hadoop111 节点格式化 NameNode 注意：格式化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。\n1 hdfs namenode -format 各个模块分开启动**/**停止（配置 ssh **是前提）\n启动/停止 HDFS\n1 sbin/start-dfs.sh / sbin/stop-dfs.sh 在配置了 ResourceManager 的节点（hadoop112）启动/停止 YARN\n1 sbin/start-yarn.sh / sbin/stop-yarn.sh 在 hadoop111 启动/停止历史服务器\n1 mapred --daemon start historyserver / mapred --daemon stop historyserver 各个服务组件逐一启动/停止\n分别启动/停止 HDFS 组件\n1 hdfs --daemon start/stop namenode/datanode/secondarynamenode 启动/停止 YARN\n1 yarn --daemon start/stop resourcemanager/nodemanager ","permalink":"http://localhost:1313/posts/env/hadoop%E5%AE%89%E8%A3%85/","summary":"\u003ch1 id=\"hadoop-环境配置\"\u003eHadoop 环境配置\u003c/h1\u003e\n\u003ch2 id=\"修改网络配置\"\u003e修改网络配置\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e修改hosts\n\u003cimg alt=\"image-20240320103357773\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240320103357773.png\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"虚拟机安装-jdk\"\u003e虚拟机安装 JDK\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e用\u003c/strong\u003e \u003cstrong\u003eXShell\u003c/strong\u003e \u003cstrong\u003e传输工具将\u003c/strong\u003e \u003cstrong\u003eJDK\u003c/strong\u003e \u003cstrong\u003e导入到\u003c/strong\u003e \u003cstrong\u003eopt\u003c/strong\u003e \u003cstrong\u003e目录下面的\u003c/strong\u003e \u003cstrong\u003esoftware\u003c/strong\u003e \u003cstrong\u003e文件夹下面\u003c/strong\u003e\n\u003cimg alt=\"image-20240327144635195\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240327144635195.png\"\u003e\u003c/p\u003e","title":"Hadoop安装"},{"content":"虚拟机 安装虚拟机 打开虚拟机软件 新建虚拟机\n点击新建虚拟机后，选择自定义(高级) 点击下一步，知道出现下面页面，选择稍后安装操作系统 然后点击下一步，直到出现如图所示，然后修改名称和存储位置 分配处理器内核总数\n为虚拟分配内存，根据电脑来修改自己的分配 点击下一步，直到为磁盘分配大小\n一直下一步，点击完成即可\n安装centos系统\n配置镜像文件 开启虚拟机，出现下面界面以后，回车等待加载 出现下面页面，选择语言 在下面页面配置时间，软件安装，安装位置，网络和主机名\n点击时间，进行修改 点击软件安装 点击安装位置 点击网络和主机名 开始安装，并设置 root 用户和普通用户 完成后重启，进入以下界面 配置网络环境 配置虚拟机网络环境\n右键单机桌面，打开终端 在终端四输入 # vim /etc/sysconfig/network-scripts/ifcfg-ens33 进入编辑页面\n修改个人信息，具体信息如下图显示 在终端输入 # systemctl restart network 重启网络服务 重启成功后 输入在终端输入 #ifconfig 查看图片中标记的地方是否与自己修改的一致，若没有修改成功，则再次重复上面配置虚拟机网络环境的操做 修改用户名 配置windos网络环境\n在自己的 windos 电脑中进入 C:/Windos/System32/drivers/etc 找到hosts文件进修配置修改。 测试连接虚拟机 Xsehll Xftp安装 安装地址https://www.xshell.com/zh/free-for-home-school 具体安装步骤省略 通过 Xshell 连接虚拟机 成功连接后会出现以下界面 测试 Xftp 是否可以使用 基本环境配置 在终端输入 ping www.baidu.com 出现下面界面即网络正常 安装 epel-release\n1 yum install -y epel-release 注：Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方 repository 中是找不到的） 关闭防火墙，并停止开机自启动 systemctl stop firewalld systemctl disable firewalld.service 给 普通用户 赋予 root 权限，后期方便普通用户使用 root 权限\n1 vim /etc/sudoers 在 /opt 目录下创建文件夹，并修改所属主和所属组\n在/opt 目录下创建 module、software 文件夹 1 2 mkdir /opt/module mkdir /opt/software 修改 module、software 文件夹的所有者和所属组均为 haitang 用户，并查看 module、software 文件夹的所有者和所属组 1 2 chown atguigu:atguigu /opt/module chown atguigu:atguigu /opt/software 卸载电脑自带 JDK\n1 rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps ➢ rpm -qa：查询所安装的所有 rpm 软件包\n➢ grep -i：忽略大小写\n➢ xargs -n1：表示每次只传递一个参数\n➢ rpm -e –nodeps：强制卸载软件\n重启虚拟机\n1 reboot ​虚拟机安装结束\n","permalink":"http://localhost:1313/posts/env/virtual-machine-installation/","summary":"\u003ch1 id=\"虚拟机\"\u003e虚拟机\u003c/h1\u003e\n\u003ch2 id=\"安装虚拟机\"\u003e安装虚拟机\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e打开虚拟机软件\u003c/strong\u003e\n\u003cimg alt=\"image-20240313104844434\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313104844434.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e新建虚拟机\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e点击新建虚拟机后，选择自定义(高级)\n\u003cimg alt=\"image-20240313105024957\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313105024957.png\"\u003e\u003c/li\u003e\n\u003cli\u003e点击下一步，知道出现下面页面，选择\u003cstrong\u003e稍后安装操作系统\u003c/strong\u003e\n\u003cimg alt=\"image-20240313105433384\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313105433384.png\"\u003e\u003c/li\u003e\n\u003cli\u003e然后点击下一步，直到出现如图所示，然后\u003cstrong\u003e修改名称和存储位置\u003c/strong\u003e\n\u003cimg alt=\"image-20240313105706614\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313105706614.png\"\u003e\n\u003cul\u003e\n\u003cli\u003e分配处理器内核总数\u003cbr\u003e\n\u003cimg alt=\"image-20240313105903312\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313105903312.png\"\u003e\u003c/li\u003e\n\u003cli\u003e为虚拟分配内存，根据电脑来修改自己的分配\n\u003cimg alt=\"image-20240313110033065\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313110033065.png\"\u003e\u003c/li\u003e\n\u003cli\u003e点击下一步，直到为磁盘分配大小\u003cbr\u003e\n\u003cimg alt=\"image-20240313110205690\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313110205690.png\"\u003e\u003c/li\u003e\n\u003cli\u003e一直下一步，点击完成即可\u003cbr\u003e\n\u003cimg alt=\"image-20240313110241122\" loading=\"lazy\" src=\"https://cdn.jsdelivr.net/gh/Ahaitang/PicGo@master/Images/image-20240313110241122.png\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e安装centos系统\u003c/strong\u003e\u003c/p\u003e","title":"虚拟机安装——CentOS"},{"content":"今日突发奇想，便有了这篇文字。\n此处开始为正文\n","permalink":"http://localhost:1313/posts/life/%E9%97%B2%E6%9A%87%E5%B0%8F%E8%AE%B03/","summary":"\u003cp\u003e今日突发奇想，便有了这篇文字。\u003c/p\u003e","title":"闲暇小记—3"},{"content":"课上突发奇想写下这篇文字，记录一下自己的想法。\n写这篇文字只是为了吐槽学校的某个 J 老师，真的不知道这个老师到底在想什么，从一开始接触这个老师我就不喜欢他，近期发生的事情更是让我觉得无语。（具体什么事情就不说了，博主只是一个学院中的普通蒻鸡，还不敢实名吐槽某系主任）。说实话从大一开始知道这个老师到大二这个老师带我们的课，再到如今大三，中间所有接触到的或者间接了解到的都让我十分讨厌这个老师。\n就这么多吧，写这么多如果知道的或者认识的同学看到第一句就知道了，不知道也没要去给自己增加烦心事。 ctm\n","permalink":"http://localhost:1313/posts/life/%E9%97%B2%E6%9A%87%E5%B0%8F%E8%AE%B02/","summary":"去做风吧 做不被定义的风  去造梦吧 就算世界都不懂","title":"闲暇小记 2"},{"content":"此处内容将会出现在摘要（summary）里\n# 此处的“\\”用于转义，否则无法正常显示，实际使用须删去。\r此处开始为正文\n","permalink":"http://localhost:1313/posts/env/flink%E5%AE%89%E8%A3%85/","summary":"\u003cp\u003e此处内容将会出现在摘要（summary）里\u003c/p\u003e\n\u003c!--\\more--\u003e # 此处的“\\”用于转义，否则无法正常显示，实际使用须删去。\r\n\u003cp\u003e此处开始为正文\u003c/p\u003e","title":"Flink安装"},{"content":"此处内容将会出现在摘要（summary）里\n# 此处的“\\”用于转义，否则无法正常显示，实际使用须删去。\r文章转载至牛客网\nHadoop面试题 1. HDFS的写流程 客户端向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。 NameNode返回是否可以上传。 客户端请求上传第一个block（第一个block与第二个block有一定的区别），通过域名端口找到DataNode。 DataNode收到请求之后，向客户端返回一个流。 客户端开始往这个流中写数据。 客户端写完一个block之后，请求NameNode上传第二个block。 重复3-6的步骤。 2. HDFS的读流程 客户端向NameNode请求下载文件，NameNode通过查询元数据，找到文件的block所在的DataNode。 挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。 DataNode开始传输数据给客户端。 客户端从多个DataNode上读取数据。 3. HDFS的文件删除流程 客户端请求NameNode删除文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以删除。 NameNode执行删除标记。 NameNode返回是否删除成功。 4. HDFS的文件复制流程 客户端请求NameNode复制文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以复制。 NameNode执行复制标记。 NameNode返回是否复制成功。 5. HDFS的文件追加流程 客户端请求NameNode追加文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以追加。 NameNode执行追加标记。 NameNode返回是否追加成功。 6. HDFS的文件重命名流程 客户端请求NameNode重命名文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以重命名。 NameNode执行重命名标记。 NameNode返回是否重命名成功。 7. HDFS的文件权限修改流程 客户端请求NameNode修改文件权限。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以修改权限。 NameNode执行修改权限标记。 NameNode返回是否修改权限成功。 ","permalink":"http://localhost:1313/posts/learn/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E9%A2%98%E5%BA%931/","summary":"\u003cp\u003e此处内容将会出现在摘要（summary）里\u003c/p\u003e\n\u003c!--\\more--\u003e # 此处的“\\”用于转义，否则无法正常显示，实际使用须删去。\r\n\u003cp\u003e文章转载至牛客网\u003c/p\u003e\n\u003ch2 id=\"hadoop面试题\"\u003eHadoop面试题\u003c/h2\u003e\n\u003ch3 id=\"1-hdfs的写流程\"\u003e1. HDFS的写流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否可以上传。\u003c/li\u003e\n\u003cli\u003e客户端请求上传第一个block（第一个block与第二个block有一定的区别），通过域名端口找到DataNode。\u003c/li\u003e\n\u003cli\u003eDataNode收到请求之后，向客户端返回一个流。\u003c/li\u003e\n\u003cli\u003e客户端开始往这个流中写数据。\u003c/li\u003e\n\u003cli\u003e客户端写完一个block之后，请求NameNode上传第二个block。\u003c/li\u003e\n\u003cli\u003e重复3-6的步骤。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"2-hdfs的读流程\"\u003e2. HDFS的读流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端向NameNode请求下载文件，NameNode通过查询元数据，找到文件的block所在的DataNode。\u003c/li\u003e\n\u003cli\u003e挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。\u003c/li\u003e\n\u003cli\u003eDataNode开始传输数据给客户端。\u003c/li\u003e\n\u003cli\u003e客户端从多个DataNode上读取数据。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"3-hdfs的文件删除流程\"\u003e3. HDFS的文件删除流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode删除文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以删除。\u003c/li\u003e\n\u003cli\u003eNameNode执行删除标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否删除成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"4-hdfs的文件复制流程\"\u003e4. HDFS的文件复制流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode复制文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以复制。\u003c/li\u003e\n\u003cli\u003eNameNode执行复制标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否复制成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"5-hdfs的文件追加流程\"\u003e5. HDFS的文件追加流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode追加文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以追加。\u003c/li\u003e\n\u003cli\u003eNameNode执行追加标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否追加成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"6-hdfs的文件重命名流程\"\u003e6. HDFS的文件重命名流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode重命名文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以重命名。\u003c/li\u003e\n\u003cli\u003eNameNode执行重命名标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否重命名成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"7-hdfs的文件权限修改流程\"\u003e7. HDFS的文件权限修改流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode修改文件权限。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以修改权限。\u003c/li\u003e\n\u003cli\u003eNameNode执行修改权限标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否修改权限成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e","title":"大数据面试题库 1"},{"content":"此处内容将会出现在摘要（summary）里\n# 此处的“\\”用于转义，否则无法正常显示，实际使用须删去。\rHadoop面试题 1. HDFS的写流程 客户端向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。 NameNode返回是否可以上传。 客户端请求上传第一个block（第一个block与第二个block有一定的区别），通过域名端口找到DataNode。 DataNode收到请求之后，向客户端返回一个流。 客户端开始往这个流中写数据。 客户端写完一个block之后，请求NameNode上传第二个block。 重复3-6的步骤。 2. HDFS的读流程 客户端向NameNode请求下载文件，NameNode通过查询元数据，找到文件的block所在的DataNode。 挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。 DataNode开始传输数据给客户端。 客户端从多个DataNode上读取数据。 3. HDFS的文件删除流程 客户端请求NameNode删除文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以删除。 NameNode执行删除标记。 NameNode返回是否删除成功。 4. HDFS的文件复制流程 客户端请求NameNode复制文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以复制。 NameNode执行复制标记。 NameNode返回是否复制成功。 5. HDFS的文件追加流程 客户端请求NameNode追加文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以追加。 NameNode执行追加标记。 NameNode返回是否追加成功。 6. HDFS的文件重命名流程 客户端请求NameNode重命名文件。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以重命名。 NameNode执行重命名标记。 NameNode返回是否重命名成功。 7. HDFS的文件权限修改流程 客户端请求NameNode修改文件权限。 NameNode检查目标文件是否存在。 目标文件存在则返回是否可以修改权限。 NameNode执行修改权限标记。 NameNode返回是否修改权限成功。 ","permalink":"http://localhost:1313/posts/work/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E9%A2%98%E5%BA%931/","summary":"\u003cp\u003e此处内容将会出现在摘要（summary）里\u003c/p\u003e\n\u003c!--\\more--\u003e # 此处的“\\”用于转义，否则无法正常显示，实际使用须删去。\r\n\u003ch2 id=\"hadoop面试题\"\u003eHadoop面试题\u003c/h2\u003e\n\u003ch3 id=\"1-hdfs的写流程\"\u003e1. HDFS的写流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否可以上传。\u003c/li\u003e\n\u003cli\u003e客户端请求上传第一个block（第一个block与第二个block有一定的区别），通过域名端口找到DataNode。\u003c/li\u003e\n\u003cli\u003eDataNode收到请求之后，向客户端返回一个流。\u003c/li\u003e\n\u003cli\u003e客户端开始往这个流中写数据。\u003c/li\u003e\n\u003cli\u003e客户端写完一个block之后，请求NameNode上传第二个block。\u003c/li\u003e\n\u003cli\u003e重复3-6的步骤。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"2-hdfs的读流程\"\u003e2. HDFS的读流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端向NameNode请求下载文件，NameNode通过查询元数据，找到文件的block所在的DataNode。\u003c/li\u003e\n\u003cli\u003e挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。\u003c/li\u003e\n\u003cli\u003eDataNode开始传输数据给客户端。\u003c/li\u003e\n\u003cli\u003e客户端从多个DataNode上读取数据。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"3-hdfs的文件删除流程\"\u003e3. HDFS的文件删除流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode删除文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以删除。\u003c/li\u003e\n\u003cli\u003eNameNode执行删除标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否删除成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"4-hdfs的文件复制流程\"\u003e4. HDFS的文件复制流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode复制文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以复制。\u003c/li\u003e\n\u003cli\u003eNameNode执行复制标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否复制成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"5-hdfs的文件追加流程\"\u003e5. HDFS的文件追加流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode追加文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以追加。\u003c/li\u003e\n\u003cli\u003eNameNode执行追加标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否追加成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"6-hdfs的文件重命名流程\"\u003e6. HDFS的文件重命名流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode重命名文件。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以重命名。\u003c/li\u003e\n\u003cli\u003eNameNode执行重命名标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否重命名成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"7-hdfs的文件权限修改流程\"\u003e7. HDFS的文件权限修改流程\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003col\u003e\n\u003cli\u003e客户端请求NameNode修改文件权限。\u003c/li\u003e\n\u003cli\u003eNameNode检查目标文件是否存在。\u003c/li\u003e\n\u003cli\u003e目标文件存在则返回是否可以修改权限。\u003c/li\u003e\n\u003cli\u003eNameNode执行修改权限标记。\u003c/li\u003e\n\u003cli\u003eNameNode返回是否修改权限成功。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e","title":"大数据面试题库 1"},{"content":"一个普普通通的大学生\n就读于数据科学与大数据技术专业\n目前正在努力学习想要找到一份好的工作，也希望能在这个过程中能学到更多的知识。\n当然也不希望一直的当 SQL Boy, 希望能有开更高级开发的机会。\n也希望能在这个过程中，能和大家一起交流，一起进步。\n","permalink":"http://localhost:1313/about/","summary":"about","title":"🙋🏻‍♂️ 关于"},{"content":"\r我的朋友们\rGitHub\rGitHub is the world\u0026#39;s largest software development platform.\rBilibili\rBilibili is a Chinese video website.\rPink-29的博客\r分享一些技术文章(UP 的好伙伴)\rBFS的博客\r分享一些技术文章(UP 的好伙伴)\rChouXiaoZilwh的博客\r分享一些技术文章(UP 的好伙伴)\r","permalink":"http://localhost:1313/links/","summary":"links","title":"🤝友链"}]